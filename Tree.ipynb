{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba.analyse#用于分词\n",
    "from sklearn.model_selection import train_test_split#用于分割数据集\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer#用于特征提取\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID                       Title Subject\n",
      "0  1841                       文艺民俗学      文学\n",
      "1    77     近二十年来专业指挥参与群众业余合唱的观察与思考    人文地理\n",
      "2  2609  习近平新时代绿色发展观视域下中国海洋生态环境保护省思    环境科学\n",
      "3   407            抗战时期中日两国在东南亚的宣传战     历史学\n",
      "4  1971                博采众长的《批评的解剖》      文学\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "data=pd.read_excel('社会科学标题数据集-200/train200.xlsx')\n",
    "data.columns = ['ID','Title','Subject']\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['文艺民俗学', '近二十年来专业指挥参与群众业余合唱的观察与思考', '习近平新时代绿色发展观视域下中国海洋生态环境保护省思', '抗战时期中日两国在东南亚的宣传战', '博采众长的《批评的解剖》', '口述档案与裕固族文化的传承', '对指标体系好坏衡量标准的探讨', '对政府机构改革之深层次探讨', '从社会物质关系透视“权利、法律和犯罪”——马克思对施蒂纳的批判', '国内外关于俄巴的研究现状综述']\n"
     ]
    }
   ],
   "source": [
    "# 读取title数据\n",
    "title_list=data['Title'].tolist()\n",
    "print(title_list[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3960\n",
      "['文学', '人文地理', '环境科学', '历史学', '文学', '民族学', '统计学', '政治学', '马克思主义', '民族学']\n"
     ]
    }
   ],
   "source": [
    "# 所有类别\n",
    "category_list=data['Subject'].tolist()\n",
    "print(len(category_list))\n",
    "print(category_list[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['民俗学', '文艺'], ['合唱', '业余', '二十年'], ['视域', '省思', '习近平'], ['宣传战', '抗战时期', '中日'], ['博采众长', '解剖', '批评'], ['裕固族', '口述', '传承'], ['衡量标准', '指标体系', '好坏'], ['深层次', '探讨', '改革'], ['施蒂纳', '透视', '马克思'], ['俄巴', '综述', '现状']]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "keywords_list=[]\n",
    "for text in title_list:\n",
    "    keywords_list.append(jieba.analyse.extract_tags(text,topK=3,withWeight=False,allowPOS=()))\n",
    "print(keywords_list[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['民俗学 文艺', '合唱 业余 二十年', '视域 省思 习近平', '宣传战 抗战时期 中日', '博采众长 解剖 批评', '裕固族 口述 传承', '衡量标准 指标体系 好坏', '深层次 探讨 改革', '施蒂纳 透视 马克思', '俄巴 综述 现状']\n"
     ]
    }
   ],
   "source": [
    "all_keywords=[]\n",
    "for keyword in keywords_list:\n",
    "    all_keywords.append(' '.join(keyword))\n",
    "print(all_keywords[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2772, 4910)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(1188, 4910)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['exp', 'lex', '①①', '①②', '①③', '①④', '①⑤', '①⑥', '①⑦', '①⑧', '①⑨', '①ａ', '①ｂ', '①ｃ', '①ｄ', '①ｅ', '①ｆ', '①ｇ', '①ｈ', '①ｉ', '①ｏ', '②①', '②②', '②③', '②④', '②⑤', '②⑥', '②⑦', '②⑧', '②⑩', '②ａ', '②ｂ', '②ｄ', '②ｅ', '②ｆ', '②ｇ', '②ｈ', '②ｉ', '②ｊ', '③①', '③⑩', '③ａ', '③ｂ', '③ｃ', '③ｄ', '③ｅ', '③ｆ', '③ｇ', '③ｈ', '④ａ', '④ｂ', '④ｃ', '④ｄ', '④ｅ', '⑤ａ', '⑤ｂ', '⑤ｄ', '⑤ｅ', '⑤ｆ', '１２', 'ｌｉ', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# 分割数据集\n",
    "with open ('stop.txt','r',encoding='utf-8') as f:\n",
    "    stopwords=f.read()\n",
    "    stopwords=stopwords.split('\\n')\n",
    "data=np.array(all_keywords)\n",
    "labels=np.array(category_list)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(data,labels,test_size=0.3,random_state=1)\n",
    "\n",
    "count_vec=CountVectorizer(binary=True,stop_words=stopwords)\n",
    "X_train=count_vec.fit_transform(X_train)\n",
    "print(X_train.shape)\n",
    "print(X_train.toarray()[0:10])\n",
    "X_test=count_vec.transform(X_test)\n",
    "print(X_test.shape)\n",
    "print(X_test.toarray()[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1188, 4910)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['文学', '管理学', '新闻传播学', '民族学', '哲学', '统计学', '宗教学', '法学', '艺术学', '经济学', '环境科学', '语言学', '历史学', '考古学', '图书馆、情报与文献学', '教育学', '马克思主义', '社会学', '体育学', '人文地理', '政治学', '心理学']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels=list(set(y_test))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3063973063973064"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树\n",
    "dtc=tree.DecisionTreeClassifier()\n",
    "dtc.fit(X_train,y_train)\n",
    "\n",
    "dtc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996392496392497"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[10,20],\n",
    "}\n",
    "GR=GridSearchCV(tree.DecisionTreeClassifier(),param_grid,cv=10)\n",
    "GR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 20}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11472482663688544"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GR.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1069023569023569"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最优模型\n",
    "dtc=tree.DecisionTreeClassifier(criterion='entropy',max_depth=25,min_samples_split=22,min_samples_leaf=1)\n",
    "dtc.fit(X_train,y_train)\n",
    "dtc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15692640692640691"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0 51  0  9  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  5  0  0  0  1  0  0 45  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  1  0  0 40  0  6  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  6  0  1  0  0 49  0  6  0  0  0  0  0  1  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  0  0 49  0  0  0  0  0  0  1  4  0  0  0  0  0]\n",
      " [ 0  1  1  0  0  1  0  0 46  0  5  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 57  0  2  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  3  0  0 51  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 37  0  2  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0 53  0  6  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  0 36  0 10  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 38  0  7  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 62  0  1  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 65  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 40  0  3  0  0  0  7  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0 35  0  2  0  0  0  0  8  0  0  0  0  0  4]\n",
      " [ 0  0  0  0  0  2  0  0 26  0  0  0  0  0  0  0 22  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  1  0  0 41  0  2  0  0  0  0  1  0  9  0  0  0  2]\n",
      " [ 0  0  0  0  0  0  0  0 44  0  0  0  0  0  0  0  0  0  6  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  0 50  0  5  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  4  0  0 41  0  0  0  0  0  0  0  2  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0 31  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "y_true=y_test\n",
    "y_pred=dtc.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_true,y_pred,labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          文学       0.00      0.00      0.00        61\n",
      "         管理学       0.71      0.09      0.17        53\n",
      "       新闻传播学       0.75      0.06      0.11        51\n",
      "         民族学       0.75      0.09      0.17        64\n",
      "          哲学       0.00      0.00      0.00        55\n",
      "         统计学       0.05      0.02      0.03        55\n",
      "         宗教学       0.00      0.00      0.00        60\n",
      "          法学       0.00      0.00      0.00        56\n",
      "         艺术学       0.04      0.93      0.07        40\n",
      "         经济学       0.00      0.00      0.00        62\n",
      "        环境科学       0.14      0.21      0.17        48\n",
      "         语言学       0.00      0.00      0.00        46\n",
      "         历史学       0.00      0.00      0.00        64\n",
      "         考古学       0.00      0.00      0.00        66\n",
      "  图书馆、情报与文献学       1.00      0.14      0.24        51\n",
      "         教育学       0.73      0.16      0.26        50\n",
      "       马克思主义       0.71      0.43      0.54        51\n",
      "         社会学       1.00      0.16      0.28        56\n",
      "         体育学       1.00      0.12      0.21        50\n",
      "        人文地理       0.00      0.00      0.00        57\n",
      "         政治学       0.67      0.04      0.08        50\n",
      "         心理学       0.50      0.26      0.34        42\n",
      "\n",
      "    accuracy                           0.11      1188\n",
      "   macro avg       0.37      0.12      0.12      1188\n",
      "weighted avg       0.35      0.11      0.11      1188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred,labels=labels))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25429dbb76d0c9414b6779ba2f705fe02677cbfbefaaf3a0e0e921f1c53ce1da"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
