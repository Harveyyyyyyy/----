{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                    Title Subject\n",
      "0   0     甲午中日战争至甲辰日俄战争期间东北亚局势    人文地理\n",
      "1   1           以事业为己任——记周光复教授    人文地理\n",
      "2   2         大饥荒年代非正常死亡的另一种计算    人文地理\n",
      "3   3               鲁迅小说中的女性世界    人文地理\n",
      "4   4  基于语料库的英汉光亮类词语研究：认知语义学视角    人文地理\n",
      "['甲午中日战争至甲辰日俄战争期间东北亚局势', '以事业为己任——记周光复教授', '大饥荒年代非正常死亡的另一种计算', '鲁迅小说中的女性世界', '基于语料库的英汉光亮类词语研究：认知语义学视角', '按摩院里盲人师傅的心酸幽默话', '骆家辉:开动美国经济引擎的华裔部长', '南北朝时期民族迁移引起的语音变迁——以晋代吴方言的韵母为例', '宋代女性文学中食物意象的审美文化阐释——评《华夏饮食文化》', '一举多得的“城市作业本”']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba.analyse#用于分词\n",
    "from sklearn.model_selection import train_test_split#用于分割数据集\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer#用于特征提取\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "# 读取数据\n",
    "data=pd.read_excel('社会科学标题数据集-200/data_200_each_discipline.xlsx')\n",
    "data.columns = ['ID','Title','Subject']\n",
    "print(data.head())\n",
    "# 读取title数据\n",
    "title_list=data['Title'].tolist()\n",
    "print(title_list[0:10])\n",
    "# 所有类别(重复)\n",
    "category_list=data['Subject'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['政治学', '语言学', '新闻传播学', '体育学', '文学', '经济学', '心理学', '法学', '图书馆、情报与文献学', '宗教学', '教育学', '民族学', '环境科学', '马克思主义', '历史学', '人文地理', '考古学', '哲学', '艺术学', '社会学', '统计学', '管理学']\n"
     ]
    }
   ],
   "source": [
    "#所有类别\n",
    "category=(list(set(category_list)))\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.169 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['甲午 中日战争 至 甲辰 日俄战争 期间 东北亚 局势', '以 事业 为 己任 — — 记周 光复 教授', '大 饥荒 年代 非正常 死亡 的 另 一种 计算', '鲁迅 小说 中 的 女性 世界', '基于 语料库 的 英汉 光亮 类 词语 研究 ： 认知 语义学 视角', '按摩院 里 盲人 师傅 的 心酸 幽默 话', '骆家辉 : 开动 美国 经济 引擎 的 华裔 部长', '南北朝 时期 民族 迁移 引起 的 语音 变迁 — — 以 晋代 吴方言 的 韵母 为例', '宋代 女性 文学 中 食物 意象 的 审美 文化 阐释 — — 评 《 华夏 饮食文化 》', '一举多得 的 “ 城市 作业本 ”']\n",
      "['人文地理', '人文地理', '人文地理', '人文地理', '人文地理', '人文地理', '人文地理', '人文地理', '人文地理', '人文地理']\n"
     ]
    }
   ],
   "source": [
    "with open ('stop.txt','r',encoding='utf-8') as f:\n",
    "    stopwords=f.read()\n",
    "    stopwords=stopwords.split('\\n')\n",
    "#分词\n",
    "title_list_cut=[]\n",
    "for title in title_list:\n",
    "    word=jieba.lcut(title)\n",
    "    if word not in stopwords:\n",
    "        title_list_cut.append(' '.join(word))\n",
    "print(title_list_cut[0:10])\n",
    "print(category_list[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3080, 5000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['exp', 'lex', '①①', '①②', '①③', '①④', '①⑤', '①⑥', '①⑦', '①⑧', '①⑨', '①ａ', '①ｂ', '①ｃ', '①ｄ', '①ｅ', '①ｆ', '①ｇ', '①ｈ', '①ｉ', '①ｏ', '②①', '②②', '②③', '②④', '②⑤', '②⑥', '②⑦', '②⑧', '②⑩', '②ａ', '②ｂ', '②ｄ', '②ｅ', '②ｆ', '②ｇ', '②ｈ', '②ｉ', '②ｊ', '③①', '③⑩', '③ａ', '③ｂ', '③ｃ', '③ｄ', '③ｅ', '③ｆ', '③ｇ', '③ｈ', '④ａ', '④ｂ', '④ｃ', '④ｄ', '④ｅ', '⑤ａ', '⑤ｂ', '⑤ｄ', '⑤ｅ', '⑤ｆ', '１２', 'ｌｉ', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# 进行数据分割\n",
    "x_train,x_test,y_train,y_test=train_test_split(title_list_cut,category_list,test_size=0.3,random_state=22)\n",
    "# 对数据集进行特征抽取\n",
    "tf = TfidfVectorizer(stop_words=stopwords)\n",
    "x_train = tf.fit_transform(x_train)\n",
    "x_test = tf.transform(x_test)\n",
    "\n",
    "\n",
    "# 对数据集进行特征选择\n",
    "f_classif(x_train,y_train)\n",
    "selector = SelectKBest(f_classif, k=5000)\n",
    "selector.fit(x_train, y_train)\n",
    "x_train = selector.transform(x_train)\n",
    "x_test = selector.transform(x_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3181818181818182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树\n",
    "dtc=tree.DecisionTreeClassifier()\n",
    "dtc.fit(x_train,y_train)\n",
    "\n",
    "dtc.score(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811688311688311"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 15]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[10,15]\n",
    "}\n",
    "GR=GridSearchCV(tree.DecisionTreeClassifier(),param_grid,cv=5)\n",
    "GR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 15}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16428571428571428"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GR.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16893939393939394"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最优模型\n",
    "dtc=tree.DecisionTreeClassifier(criterion='gini',max_depth=15)\n",
    "dtc.fit(x_train,y_train)\n",
    "dtc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2237012987012987"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0  0  4  0  0  0  2  0  1  1  0  1  0  0 40  0  0  0  0  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 50  0  0  0  0  0]\n",
      " [ 2  0 11  0  1  0  0  0  0  0  1  0  0  1  0  0 41  0  0  0  0  0]\n",
      " [ 0  0  0 15  0  0  1  0  0  0  1  0  0  0  0  0 35  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0 70  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  1  0  0  0  0  0  0  0  2  0  0 54  0  0  0  0  2]\n",
      " [ 0  0  0  0  0  0 11  0  0  0  2  0  0  0  0  0 52  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  1  0 52  0  0  0  0  1]\n",
      " [ 0  0  1  0  0  0  0  2 17  0  0  0  0  0  0  0 40  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0  0  5  0  1  0  0  0  0 43  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  1  0  0  0 21  0  0  2  0  0 37  1  0  1  0  0]\n",
      " [ 1  0  1  0  0  0  0  0  0  0  2 12  0  0  0  0 44  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  4  1  1  0  0  0 55  0  0  0  0  3]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  1  0 24  0  0 25  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0 51  0  0  1  0  1]\n",
      " [ 1  0  0  0  0  0  1  0  0  0  0  7  0  0  0  0 62  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 55  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0 49  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  2  0  0  1  0  0  0  0  0  0 54  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  1  0  0  0  0 36  0  0 19  0  0]\n",
      " [ 0  0  2  0  0  0  1  1  0  0  0  1  0  0  0  0 61  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  1  0  0  1  0  1  0  0  0  0  0 42  0  0  1  0 10]]\n"
     ]
    }
   ],
   "source": [
    "y_true=y_test\n",
    "y_pred=dtc.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_true,y_pred,labels=category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         政治学       0.48      0.18      0.26        62\n",
      "         语言学       0.00      0.00      0.00        51\n",
      "       新闻传播学       0.52      0.19      0.28        57\n",
      "         体育学       1.00      0.29      0.45        52\n",
      "          文学       0.00      0.00      0.00        74\n",
      "         经济学       0.50      0.02      0.03        60\n",
      "         心理学       0.65      0.17      0.27        65\n",
      "          法学       0.77      0.16      0.26        64\n",
      "  图书馆、情报与文献学       0.85      0.28      0.42        60\n",
      "         宗教学       0.83      0.09      0.17        53\n",
      "         教育学       0.57      0.33      0.42        63\n",
      "         民族学       0.46      0.20      0.28        61\n",
      "        环境科学       1.00      0.02      0.03        64\n",
      "       马克思主义       0.60      0.44      0.51        54\n",
      "         历史学       0.00      0.00      0.00        56\n",
      "        人文地理       0.00      0.00      0.00        71\n",
      "         考古学       0.05      1.00      0.10        55\n",
      "          哲学       0.00      0.00      0.00        58\n",
      "         艺术学       0.00      0.00      0.00        59\n",
      "         社会学       0.83      0.33      0.47        58\n",
      "         统计学       0.00      0.00      0.00        66\n",
      "         管理学       0.50      0.18      0.26        57\n",
      "\n",
      "    accuracy                           0.17      1320\n",
      "   macro avg       0.44      0.18      0.19      1320\n",
      "weighted avg       0.43      0.17      0.19      1320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred,labels=category))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25429dbb76d0c9414b6779ba2f705fe02677cbfbefaaf3a0e0e921f1c53ce1da"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
